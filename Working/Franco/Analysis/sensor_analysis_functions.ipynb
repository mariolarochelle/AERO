{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "import math\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.tsa.api as smt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import itertools\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from operator import itemgetter\n",
    "from itertools import *\n",
    "\n",
    "import plotly.offline as pyo\n",
    "import plotly_express as px\n",
    "import plotly.graph_objs as go\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fault_detection(df, sensor='anem', correlation_window = 10, ratio_th = 10, correlation_th = .7, diff_th = .1):\n",
    "    \"\"\" Función construir estadísticas de los datos\n",
    "    \n",
    "        df: dataframe\n",
    "        sensor: 'anem' anemometer, 'vane' windvane\n",
    "        func: 'correlation', 'ratio', 'diff', 'all'\n",
    "        correlation_window: default=10. Ventana de correlación\n",
    "\n",
    "        return: Dataframe con las stats nuevas\n",
    "    \"\"\"\n",
    "    if sensor.lower() == 'anem':\n",
    "        func = ['correlation', 'ratio']\n",
    "    elif sensor.lower() == 'vane':\n",
    "        func = ['diff']\n",
    "    \n",
    "    \n",
    "    str_sensor = ['timestamp']\n",
    "    str_sensor.append(sensor)\n",
    "    \n",
    "    ch_sensors = [x for x in df.columns if any(i.lower() in x.lower() for i in str_sensor)]\n",
    "    df_sensors = df.loc[:, ch_sensors]\n",
    "\n",
    "    if sensor == 'vane':\n",
    "        func_column = '_deg_cos'\n",
    "        for col in df_sensors.columns[~df_sensors.columns.str.contains('Timestamp')]:\n",
    "            df_sensors[str(col) + '-cos*'] = np.sin(np.deg2rad(df_sensors[col])) \n",
    "    \n",
    "    \n",
    "    for x in itertools.combinations(df_sensors.columns[~df_sensors.columns.str.contains('Timestamp')], 2):\n",
    "        \n",
    "        # Fractions\n",
    "        if ('ratio' in func) or ('all' in func):\n",
    "            ratio_col_name = str(x[0] + 'VS' + x[1] + '_ratio*')\n",
    "            df_sensors[ratio_col_name] = df_sensors[x[0]] / df_sensors[x[1]]\n",
    "            \n",
    "            df_sensors[ratio_col_name + '_anomaly'] = ''\n",
    "            df_sensors.loc[df_sensors[ratio_col_name] >= ratio_th, ratio_col_name + '_anomaly'] = 1\n",
    "            df_sensors.loc[df_sensors[ratio_col_name] < ratio_th, ratio_col_name + '_anomaly'] = 0\n",
    "            #df_sensors.loc[df_sensors[ratio_col_name] < 0.4, ratio_col_name + '_anomaly'] = 1\n",
    "            \n",
    "        # Rolling correlations           \n",
    "        if ('correlation' in func) or ('all' in func):\n",
    "            correlation_col_name = str(x[0] + 'VS' + x[1] + '_correlation*')\n",
    "            \n",
    "            #rolling_correlation = df_sensors[x[0]].rolling(correlation_window).corr(df_sensors[x[1]].rolling(correlation_window)).shift(2)\n",
    "            rolling_correlation = [np.corrcoef(df_sensors.loc[idx-correlation_window:idx, x[0]].values, df_sensors.loc[idx-correlation_window:idx, x[1]].values)[0][1] for idx, _ in df_sensors.iterrows()]\n",
    "            \n",
    "            \n",
    "            df_sensors[correlation_col_name] = rolling_correlation\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            df_sensors[correlation_col_name + '_anomaly'] = ''\n",
    "            df_sensors.loc[df_sensors[correlation_col_name] <= correlation_th, correlation_col_name + '_anomaly'] = 1\n",
    "            df_sensors.loc[df_sensors[correlation_col_name] > correlation_th, correlation_col_name + '_anomaly'] = 0\n",
    "            \n",
    "\n",
    "        # Difference\n",
    "        if ('diff' in func) or ('all' in func):\n",
    "            if '-cos' in x[0] and '-cos' in x[1]:\n",
    "                diff_col_name = str(x[0] + 'VS' + x[1] + '_diff*')\n",
    "                df_sensors[diff_col_name] = df_sensors[x[0]] - df_sensors[x[1]]\n",
    "                df_sensors[diff_col_name + '_anomaly'] = ''\n",
    "                df_sensors.loc[df_sensors[diff_col_name] >= diff_th, diff_col_name + '_anomaly'] = 1\n",
    "                df_sensors.loc[df_sensors[diff_col_name] < diff_th, diff_col_name + '_anomaly'] = 0\n",
    "                df_sensors.loc[df_sensors[diff_col_name] <= -diff_th, diff_col_name + '_anomaly'] = 1                \n",
    "    \n",
    "    return df_sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anemometer_identification(df_stats, ratio_th = 10, correlation_th = .7, window = 10):\n",
    "    \n",
    "    df_to_return = df_stats.copy()\n",
    "    df_stast = df_stats.copy()\n",
    "    \n",
    "\n",
    "    df_stats.replace('', 0, inplace=True)\n",
    "    \n",
    "    df_anomaly_column = df_stats[df_stats.columns[df_stats.columns.str.contains('anomaly')]]\n",
    "    df_anomaly = df_anomaly_column[(df_anomaly_column > 0).any(axis=1)]\n",
    "    \n",
    "    for idx, row in tqdm(df_anomaly.iterrows(), total=df_anomaly.shape[0]):\n",
    "\n",
    "        keys = np.array(list(row[row>0].keys().str.split('VS|_')))\n",
    "        keys = keys.T[:2].ravel()\n",
    "\n",
    "        ch_anem_columns = np.unique(keys)\n",
    "        keys = list(set([x for x in keys if list(keys).count(x) > 2]))\n",
    "        \n",
    "        ch_anem_to_join = []\n",
    "        for col in ch_anem_columns:\n",
    "            if df_to_return.loc[idx, col] > 70:\n",
    "                ch_anem_to_join.append(col)\n",
    "\n",
    "        df_to_return.loc[idx, 'broken?'] = ','.join(np.unique(keys+ch_anem_to_join))    \n",
    "    \n",
    "    df_to_return.loc[df_to_return['broken?'] == '', 'broken?'] = 'None'\n",
    "    df_to_return.fillna('None', inplace=True)\n",
    "    return df_to_return.loc[:, ['Timestamp', 'Ch1Anem', 'Ch2Anem', 'Ch3Anem', 'Ch4Anem',\n",
    "                                'Ch5Anem', 'Ch6Anem', 'broken?']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting_anem_parameter_tunning(df, ratio_range=30, correlation_range=10):\n",
    "    \n",
    "    df_to_plot = df[df.columns[df.columns.str.contains('Anem')]]\n",
    "    \n",
    "    df_intersection = pd.DataFrame()\n",
    "    df_ratio = pd.DataFrame()\n",
    "    df_correlation = pd.DataFrame()\n",
    "    \n",
    "    \n",
    "    idx = 0\n",
    "    for ratio in tqdm(range(2, ratio_range)):\n",
    "        for correlation in range(0, correlation_range):\n",
    "            correlation = round(correlation *.1, 2)\n",
    "            df_to_plot_stats = fault_detection(df_to_plot, sensor='anem', correlation_window=10, ratio_th = ratio, correlation_th = correlation)\n",
    "        \n",
    "            ratio_cols = df_to_plot_stats.columns[df_to_plot_stats.columns.str.contains('_ratio\\*_anomaly')]\n",
    "            correlation_cols = df_to_plot_stats.columns[df_to_plot_stats.columns.str.contains('_correlation\\*_anomaly')]\n",
    "            \n",
    "            \n",
    "            count_intersection = []\n",
    "            for x in range(len(ratio_cols)):\n",
    "                count_intersection.append(len(df_to_plot_stats.loc[(df_to_plot_stats[ratio_cols[x]] == 1) & \n",
    "                                                                   (df_to_plot_stats[correlation_cols[x]] == 1), :]))\n",
    "    \n",
    "            count_intersection = sum(count_intersection)         \n",
    "            df_intersection.loc[idx, 'cant'] = count_intersection\n",
    "            df_intersection.loc[idx, 'ratio'] = ratio\n",
    "            df_intersection.loc[idx, 'correlation'] = correlation\n",
    "            df_intersection.name = 'Intersection'\n",
    "        \n",
    "            count_ratio = []\n",
    "            count_ratio.append([len(df_to_plot_stats.loc[df_to_plot_stats[col] == 1, col]) for col in ratio_cols])\n",
    "            count_ratio = sum(*count_ratio)\n",
    "            df_ratio.loc[idx, 'cant'] = count_ratio\n",
    "            df_ratio.loc[idx, 'ratio'] = ratio\n",
    "            df_ratio.loc[idx, 'correlation'] = correlation\n",
    "            df_ratio.name = 'Ratio'\n",
    "            \n",
    "            count_correlation = []\n",
    "            count_correlation.append([len(df_to_plot_stats.loc[df_to_plot_stats[col] == 1, col]) for col in correlation_cols])\n",
    "            count_correlation = sum(*count_correlation)\n",
    "            df_correlation.loc[idx, 'cant'] = count_correlation\n",
    "            df_correlation.loc[idx, 'ratio'] = ratio\n",
    "            df_correlation.loc[idx, 'correlation'] = correlation\n",
    "            df_correlation.name = 'Correlation'\n",
    "            \n",
    "            idx = idx+1\n",
    "            \n",
    "    dfs = [df_intersection, df_ratio, df_correlation]\n",
    "    \n",
    "    for df in dfs:\n",
    "        try:\n",
    "            z = np.log10(df['cant'])\n",
    "        except:\n",
    "            z = 0\n",
    "        y = df['ratio']\n",
    "        x = df['correlation']\n",
    "\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "\n",
    "        ax.scatter(x, y, z, c='r', marker='o')\n",
    "\n",
    "        ax.set_xlabel('correlation')\n",
    "        ax.set_ylabel('ratio')\n",
    "        ax.set_zlabel('cant')\n",
    "\n",
    "        plt.title(df.name)\n",
    "\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sensors(df, index_start, index_finish, sensors=[]):\n",
    "\n",
    "    time_col = df.columns[df.columns.str.contains('Time')]\n",
    "    \n",
    "    df_to_plot = df.loc[index_start - 20:index_finish+50, sensors]\n",
    "    df_to_plot['step'] = df.loc[index_start - 20:index_finish+50, time_col]\n",
    "    \n",
    "    #df_melt = df_to_plot.melt(id_vars='step', value_vars=sensors)\n",
    "    \n",
    "    #fig = px.line(df_melt, x='step', y='value', color='variable', title='Start: '+ str(df_to_plot.loc[index_start, 'step']) +' Ends: '+ str(df_to_plot.loc[index_finish, 'step']))\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=df_to_plot['step'], y=df_to_plot[sensors[0]],\n",
    "                        mode='lines+markers',\n",
    "                        name=str(sensors[0])))\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=df_to_plot['step'], y=df_to_plot[sensors[1]],\n",
    "                        mode='lines+markers',\n",
    "                        name=str(sensors[1])))\n",
    "\n",
    "    fig.layout.update(\n",
    "        title=go.layout.Title(\n",
    "            text='Start: '+ str(df_to_plot.loc[index_start, 'step']) +' Ends: '+ str(df_to_plot.loc[index_finish, 'step']),\n",
    "    ))\n",
    "    \n",
    "    #fig.show(=)    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_list(df, sensor):\n",
    "    df.loc[df['broken?'].str.contains(sensor), sensor + '_index'] = 1\n",
    "    df.loc[~df['broken?'].str.contains(sensor), sensor + '_index'] = 0\n",
    "\n",
    "    indexes = df.loc[df[sensor + '_index'] == 1, :].index\n",
    "\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_kneighbor_indexes(number_list, k):\n",
    "    \n",
    "    groups = []\n",
    "    start = 0\n",
    "    \n",
    "    for idx, val in enumerate(number_list[1:], start = 1):\n",
    "        if number_list[idx] - number_list[idx-1]  > k:\n",
    "            stop = idx\n",
    "            groups.append(number_list[start:stop])\n",
    "            start = stop + 1\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    groups = [x for x in groups if x.size > 5]\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dashboard(df, redundance_dict={}):\n",
    "    anem_columns = df.columns[df.columns.str.contains('Anem')]\n",
    "    \n",
    "    anem_dict = {}\n",
    "    for col in anem_columns:\n",
    "        indexes = get_index_list(df, col) \n",
    "        anem_dict[col] = split_kneighbor_indexes(indexes, 12)\n",
    "    \n",
    "    \n",
    "    dir_name = str(df.name)\n",
    "    try:\n",
    "        os.makedirs(dir_name)\n",
    "    except:\n",
    "        print(\"Already exists...\")\n",
    "        \n",
    "    for key, values in anem_dict.items():\n",
    "        \n",
    "        html = '<html><body>' \n",
    "        try:\n",
    "            os.makedirs(f'anomaly_html/{dir_name}/{key}')\n",
    "        except:\n",
    "            print(\"Already exists...\")\n",
    "            \n",
    "        for value in values:\n",
    "            fig = plot_sensors(df, value[0], value[-1], sensors=[key, redundance_dict[key]])\n",
    "            fig.write_html(f'anomaly_html/{dir_name}/{key}/{key}-{value[0]}.html', full_html=False)   \n",
    "    \n",
    "        cont = 0\n",
    "        for file in tqdm(sorted(glob.glob(f\"anomaly_html/{dir_name}/{key}/*.html\"), key=os.path.getmtime)):\n",
    "            html += '<div><h3> Anomalia: '+ str(cont+1) +' en el sensor: '+ key +'</h3></div>'\n",
    "            cont +=1\n",
    "            f = open(file, 'r', encoding='utf-8')\n",
    "            f = f.read()\n",
    "            html += str(f)\n",
    "\n",
    "        html += '</body></html>'\n",
    "\n",
    "        Html_file = open(f\"{dir_name}/filename_{key}.html\",\"w\")\n",
    "        Html_file.write(html)\n",
    "        Html_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anem_parameter_tunning(df, ch_anem, ratio_range=30, correlation_range=10):\n",
    "    \n",
    "    df_to_tunning = df[df.columns[df.columns.str.contains('Anem')]].copy()\n",
    "    \n",
    "    \n",
    "    \n",
    "    idx = 0\n",
    "    \n",
    "    for ratio in tqdm(range(2, ratio_range)):\n",
    "        for correlation in range(1, correlation_range):\n",
    "            correlation = round(correlation *.1, 2)\n",
    "            \n",
    "            df_fault_detection = fault_detection(df_to_tunning, sensor='anem', correlation_window=10, ratio_th=ratio, correlation_th=correlation)\n",
    "            \n",
    "            df_anem_filtered = anemometer_identification(df_vaquerias_fault_detection)\n",
    "            \n",
    "            indexes = get_index_list(df_anem_filtered, ch_anem)\n",
    "            \n",
    "            anem_dict = {}\n",
    "            #anem_dict[ch_anem] = split_kneighbor_indexes(indexes, 12)\n",
    "            print(len(split_kneighbor_indexes(indexes, 12)))           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anem_parameter_tunning(df, ratio_range=30, correlation_range=10):\n",
    "    \n",
    "    df_to_plot = df[df.columns[df.columns.str.contains('Anem')]]\n",
    "    \n",
    "    df_intersection = pd.DataFrame()\n",
    "    df_ratio = pd.DataFrame()\n",
    "    df_correlation = pd.DataFrame()\n",
    "    \n",
    "    \n",
    "    idx = 0\n",
    "    for ratio in tqdm(range(2, ratio_range)):\n",
    "        for correlation in range(0, correlation_range):\n",
    "            correlation = round(correlation *.1, 2)\n",
    "            df_to_plot_stats = fault_detection(df_to_plot, sensor='anem', correlation_window=10, ratio_th = ratio, correlation_th = correlation)\n",
    "        \n",
    "            ratio_cols = df_to_plot_stats.columns[df_to_plot_stats.columns.str.contains('_ratio\\*_anomaly')]\n",
    "            correlation_cols = df_to_plot_stats.columns[df_to_plot_stats.columns.str.contains('_correlation\\*_anomaly')]\n",
    "            \n",
    "            \n",
    "            count_intersection = []\n",
    "            for x in range(len(ratio_cols)):\n",
    "                count_intersection.append(len(df_to_plot_stats.loc[(df_to_plot_stats[ratio_cols[x]] == 1) & \n",
    "                                                                   (df_to_plot_stats[correlation_cols[x]] == 1), :]))\n",
    "    \n",
    "            count_intersection = sum(count_intersection)         \n",
    "            df_intersection.loc[idx, 'cant'] = count_intersection\n",
    "            df_intersection.loc[idx, 'ratio'] = ratio\n",
    "            df_intersection.loc[idx, 'correlation'] = correlation\n",
    "            df_intersection.name = 'Intersection'\n",
    "        \n",
    "            count_ratio = []\n",
    "            count_ratio.append([len(df_to_plot_stats.loc[df_to_plot_stats[col] == 1, col]) for col in ratio_cols])\n",
    "            count_ratio = sum(*count_ratio)\n",
    "            df_ratio.loc[idx, 'cant'] = count_ratio\n",
    "            df_ratio.loc[idx, 'ratio'] = ratio\n",
    "            df_ratio.loc[idx, 'correlation'] = correlation\n",
    "            df_ratio.name = 'Ratio'\n",
    "            \n",
    "            count_correlation = []\n",
    "            count_correlation.append([len(df_to_plot_stats.loc[df_to_plot_stats[col] == 1, col]) for col in correlation_cols])\n",
    "            count_correlation = sum(*count_correlation)\n",
    "            df_correlation.loc[idx, 'cant'] = count_correlation\n",
    "            df_correlation.loc[idx, 'ratio'] = ratio\n",
    "            df_correlation.loc[idx, 'correlation'] = correlation\n",
    "            df_correlation.name = 'Correlation'\n",
    "            \n",
    "            idx = idx+1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
